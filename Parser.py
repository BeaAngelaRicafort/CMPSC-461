import re
from typing import List, Tuple, Any, Union
from ASTNodeDefs import *

# A type alias for clarity, representing parts of expressions
# that can be a full ASTNode or a simple token tuple (like for numbers/identifiers).
ExprType = Union[ASTNode, Tuple[str, Any]]

class Lexer:
    """
    The Lexer (also known as a tokenizer or scanner) is responsible for breaking
    the raw source code string into a stream of meaningful tokens.
    """
    def __init__(self, code: str) -> None:
        """
        Initializes the Lexer.

        Args:
            code: The source code string to be tokenized.
        """
        self.code = code
        self.tokens: List[Tuple[str, Any]] = []
        # A list of tuples where each tuple contains a token name and a regex pattern.
        # The order is important, as it determines matching priority.
        self.token_specs = [
            ('NUMBER',     r'\d+'),
            ('IDENTIFIER', r'[A-Za-z_][A-Za-z0-9_]*'),
            ('IF',         r'if'),
            ('ELSE',       r'else'),
            ('FOR',        r'for'),
            ('TO',         r'to'),
            ('PRINT',      r'print'),
            ('AND',        r'and'),
            ('OR',         r'or'),
            ('NOT',        r'not'),
            ('PLUS',       r'\+'),
            ('MINUS',      r'-'),
            ('MULTIPLY',   r'\*'),
            ('DIVIDE',     r'/'),
            ('MODULO',     r'%'),
            ('EQ',         r'=='),
            ('NEQ',        r'!='),
            ('GREATER',    r'>'),
            ('LESS',       r'<'),
            ('EQUALS',     r'='),
            ('LPAREN',     r'\('),
            ('RPAREN',     r'\)'),
            ('COMMA',      r','),
            ('COLON',      r':'),
            ('SKIP',       r'[ \t\n]+'),  # Skips whitespace and newlines
            ('MISMATCH',   r'.'),         # Catches any other character
        ]
        # A single, combined regex for efficient matching.
        self.token_regex = '|'.join(f'(?P<{name}>{regex})' for name, regex in self.token_specs)

    # TODO: Implement this function
    def tokenize(self) -> List[Tuple[str, Any]]:
        """
        Why this function is needed: This is the core of the lexer. Its purpose is to
        transform the raw text-based source code into a structured list of tokens
        that the parser can understand. The parser cannot work with a raw string;
        it needs a sequence of categorized symbols.

        What this function does: It scans the input code from left to right, matching
        the text against the regular expressions defined in `self.token_specs`.
        For each match, it creates a (token_type, value) tuple and adds it to a list.
        It should handle converting numbers to integer types and correctly identifying
        keywords vs. identifiers. It discards meaningless characters like whitespace.
        The process ends when the entire code string is consumed, at which point an
        'EOF' (End of File) token is appended to signify the end of the input.
        """

        # Dictionary of Keywords - Necessary to Recognize Identifier as Keyword
        
        keywords = {
                        'if': 'IF', 
                        'else': 'ELSE', 
                        'for': 'FOR',
                        'to': 'TO',
                        'print': 'PRINT',
                        'and': 'AND',
                        'or': 'OR',
                        'not': 'NOT',

                    }

        token_list = [] # Token List - Returned at End of Function

        for token_match in re.finditer(self.token_regex, self.code): # Finds Token Matches in Inputted Code
                
                token_type = token_match.lastgroup  # .lastgroup = Returns Name of Matched Capturing Group
                token_value = token_match.group()   # .group() = Returns Matched Subgroup

                # Excludes Whitespace Tokens from Token List
                if (token_type == 'SKIP'): 
                    continue 

                # Not a Token: Raises SyntaxError 
                if (token_type == 'MISMATCH'):
                    raise SyntaxError("Invalid")
                
                # NUMBER Token: Converts Value to Integer
                if (token_type == 'NUMBER'):
                    token_value = int(token_value)
                
                # IDENTIFIER Token = Keyword 
                if (token_type == 'IDENTIFIER') and (token_value in keywords):
                    token_type = keywords[token_value]

                # Adds Token to Token List
                token_list.append((token_type, token_value))
            
        token_list.append(('EOF', None)) # Adds End of File Marker Token to Token List

        return token_list

class Parser:
    """
    The Parser takes the list of tokens generated by the Lexer and builds an
    Abstract Syntax Tree (AST). The AST is a tree representation of the source
    code's structure that is much easier to work with for later stages like
    interpretation or compilation.
    """
    def __init__(self, tokens: List[Tuple[str, Any]]) -> None:
        """
        Initializes the Parser.

        Args:
            tokens: A list of tokens from the Lexer.
        """
        self.tokens = tokens
        self.pos = 0  # The parser's current position in the token stream

    def current_token(self) -> Tuple[str, Any]:
        """A helper function to look at the current token without consuming it."""
        return self.tokens[self.pos]

    def advance(self) -> None:
        """A helper function to consume the current token and move to the next one."""
        self.pos += 1

    def expect(self, kind: str) -> Tuple[str, Any]:
        """
        Checks if the current token matches an expected type. If so, it consumes
        the token. If not, it raises a syntax error. This is crucial for
        enforcing the language's grammar rules.
        """
        if self.current_token()[0] == kind:
            token = self.current_token()
            self.advance()
            return token
        else:
            raise SyntaxError(f"Expected {kind} but got {self.current_token()[0]} at position {self.pos}")

    def parse(self) -> List[ASTNode]:
        """
        Why this function is needed: This is the main entry point for the parsing process.
        It orchestrates the entire parsing operation by repeatedly parsing the fundamental
        unit of our language: a statement.

        What this function does: It creates an empty list to hold the statements of the
        program. It then loops as long as it has not reached the 'EOF' token. In each
        iteration, it calls `parse_statement()` to parse a single statement and appends
        the resulting AST node to the list. Finally, it returns the list of statement
        nodes, which represents the complete program.
        """
        statements = []
        while self.current_token()[0] != 'EOF':
            statements.append(self.parse_statement())
        return statements

    # TODO: Implement this function
    def parse_statement(self) -> ASTNode:
        """
        Why this function is needed: Our language is composed of different kinds of statements
        (assignments, if-statements, loops, etc.). This function acts as a dispatcher. It needs
        to figure out which kind of statement is next in the token stream and call the
        correct specific function to handle it.

        What this function does: It looks at the type of the `current_token`.
        - If it's an 'IDENTIFIER', it's likely an assignment (e.g., `x = ...`).
        - If it's an 'IF', it calls `parse_if_stmt()`.
        - If it's a 'FOR', it calls `parse_for_stmt()`.
        - If it's a 'PRINT', it calls `parse_print_stmt()`.
        This routing is the essence of a top-down recursive descent parser.
        """
        token_type = self.current_token()[0]

        if (token_type == 'IDENTIFIER'): # Checks for IDENTIFIER
            identifier_token = self.current_token() # Holds IDENTIFIER
            self.advance() # Moves to Next Token
            self.expect('EQUALS') # Checks for EQUALS
            right_hand_side = self.parse_boolean_expression() # Parses Right-Hand Side
            return Assignment(('IDENTIFIER', identifier_token[1]), right_hand_side)

        elif (token_type == 'IF'): # Checks for IF
            return self.parse_if_stmt()
        
        elif (token_type == 'FOR'): # Checks for FOR
            return self.parse_for_stmt()
        
        elif (token_type == 'PRINT'): # Checks for PRINT
            return self.parse_print_stmt()
        
        else:
            raise SyntaxError("Invalid")

    # TODO: Implement this function
    def parse_if_stmt(self) -> IfStatement:
        """
        Why this function is needed: To parse the structure of an if-else statement according
        to the grammar rules.

        What this function does: It consumes the 'IF' token, then calls `parse_boolean_expression()`
        to parse the condition. It then expects and consumes a 'COLON', calls `parse_block()`
        to handle the body of the 'then' clause. After that, it checks for an 'ELSE' token to
        handle the optional else part, which also has a colon and a block. It constructs and
        returns an `IfStatement` AST node with the condition, then-block, and optional else-block.
        """

        self.expect('IF') # Checks for IF

        condition = self.parse_boolean_expression() # Parses Boolean Expression

        self.expect('COLON') # Checks for COLON

        then_block = self.parse_block() # Parses then_block

        else_block = None
        
        if (self.current_token()[0] == 'ELSE'): # Checks for ELSE (Optional)

            self.advance() # Moves to Next Token in Token List
            self.expect('COLON') # Checks for COLON
            else_block = self.parse_block() # Parses else_block

        return IfStatement(condition, then_block, else_block)

    # TODO: Implement this function
    def parse_for_stmt(self) -> ForStatement:
        """
        Why this function is needed: To parse the specific syntax of our for-loop.

        What this function does: It consumes tokens in the expected order for a for-loop:
        'FOR', an identifier for the loop variable, 'EQUALS', an expression for the start value,
        'TO', an expression for the end value, and a 'COLON'. Finally, it calls `parse_block()`
        for the loop's body. It bundles all this information into a `ForStatement` AST node.
        """
        
        self.expect('FOR') # Checks for FOR

        loop_variable = self.expect('IDENTIFIER')[1] # Checks for IDENTIFIER, Stores as Loop Variable 

        self.expect('EQUALS') # Checks for EQUALS

        start_value = self.parse_expression() # Parses start_value

        self.expect('TO') # Checks for TO

        end_value = self.parse_expression() # Parses end_value

        self.expect('COLON') # Checks for COLON

        body = self.parse_block() # Parses body

        return ForStatement(('IDENTIFIER', loop_variable), start_value, end_value, body)

    # TODO: Implement this function
    def parse_print_stmt(self) -> PrintStatement:
        """
        Why this function is needed: To handle the language's built-in print statement.

        What this function does: It consumes the 'PRINT' token and an opening parenthesis 'LPAREN'.
        It then calls `parse_arg_list()` to parse the comma-separated expressions inside the
        parentheses. Finally, it consumes the closing parenthesis 'RPAREN' and returns a
        `PrintStatement` AST node containing the list of arguments.
        """

        self.expect('PRINT') # Checks for PRINT

        self.expect('LPAREN') # Checks for LPAREN

        argument_list = self.parse_arg_list() # Parses argument_list

        self.expect('RPAREN') # Checks for RPAREN

        return PrintStatement(argument_list)

    # TODO: Implement this function
    def parse_block(self) -> Block:
        """
        Why this function is needed: Control flow statements like 'if' and 'for' need to execute
        a sequence of other statements. A 'block' represents this sequence.

        What this function does: It creates a list to hold statements. It then repeatedly calls
        `parse_statement()` to parse all statements until it reaches a token that signals the end
        of the block (in our simplified language, 'ELSE' or the end of the file). It returns a
        `Block` AST node containing the list of parsed statements.
        """

        statement_list = [] # List of Statements

        while (self.current_token()[0] in ('IDENTIFIER', 'IF', 'FOR', 'PRINT')): # Loop Until ELSE or EOF
            statement_list.append(self.parse_statement()) # Adds Parsed Statement to statement_list
        
        return Block(statement_list)

    # TODO: Implement this function
    def parse_arg_list(self) -> List[ExprType]:
        """
        Why this function is needed: To handle comma-separated lists of values, such as in the
        print statement.

        What this function does: It first parses one expression. Then, it enters a loop that
        continues as long as the current token is a 'COMMA'. Inside the loop, it consumes the
        comma and parses the next expression. It returns a list of all the parsed expression nodes.
        """
        
        parsed_argument_list = [] # List of Parsed Arguments

        parsed_argument_list.append(self.parse_boolean_expression()) # Parses First Argument

        while (self.current_token()[0] == 'COMMA'): # Loop Until No COMMA

            self.advance() # Skips COMMA, Moves to Next Token (Argument)
            parsed_argument_list.append(self.parse_boolean_expression()) # Parses Argument After COMMA

        return parsed_argument_list 

    # TODO: Implement this function
    def parse_boolean_expression(self) -> ExprType:
        """
        Why this function is needed: This function handles the logical 'OR' operator. To correctly
        implement operator precedence, we need a separate function for each level of precedence.
        'OR' has the lowest precedence among logical operators.

        What this function does: It first calls `parse_boolean_term()` to get the left-hand side.
        Then, it loops as long as it sees an 'OR' token. In the loop, it creates a `LogicalOperation`
        node with the left side, the 'OR' operator, and the result of parsing the right side.
        This left-associative structure correctly handles chains like `A or B or C`.
        """
        
        left_hand_side = self.parse_boolean_term() # Parses Expression on Left-Hand Side

        while (self.current_token()[0] == 'OR'): # Loop Until No OR

            or_token = self.current_token()[1] # Holds OR
            self.advance() # Moves to Next Token (Right-Hand Side)
            right_hand_side = self.parse_boolean_term() # Parses Expression on Right-Hand Side

            # Creates "New" Left-Hand Side
            # If More ORs (Ex: A OR B OR C ...), Right-Hand_Side -> Shifts to Left-Hand-Side, Makes Room for "New" Right-Hand Side
            left_hand_side = LogicalOperation(left_hand_side, ('OR', or_token), right_hand_side)

        return left_hand_side

    # TODO: Implement this function
    def parse_boolean_term(self) -> ExprType:
        """
        Why this function is needed: This handles the 'AND' operator, which has a higher
        precedence than 'OR'.

        What this function does: Its structure is identical to `parse_boolean_expression`, but
        it deals with the 'AND' operator and calls `parse_boolean_factor()` for its operands.
        This ensures that expressions like `A and B or C` are parsed as `(A and B) or C`.
        """
        
        left_hand_side = self.parse_boolean_factor() # Parses left_hand_side

        while (self.current_token()[0] == 'AND'): # Loop Until No AND

            and_token = self.current_token()[1] # Holds AND
            self.advance() # Moves to Next Token (Right-Hand Side)
            right_hand_side = self.parse_boolean_factor() # Parses right_hand_side

            # Creates "New" Left-Hand Side
            # If More ANDs (Ex: A AND B AND C ...): Right-Hand_Side -> Shifts to Left-Hand-Side, Makes Room for "New" Right-Hand Side
            left_hand_side = LogicalOperation(left_hand_side, ('AND', and_token), right_hand_side)

        return left_hand_side

    # TODO: Implement this function
    def parse_boolean_factor(self) -> ExprType:
        """
        Why this function is needed: This handles the unary 'NOT' operator, which has the
        highest logical precedence.

        What this function does: It checks for a 'NOT' token. If found, it consumes it,
        recursively calls `parse_boolean_factor()` to parse the expression being negated, and
        wraps it in a `UnaryOperation` node. If there is no 'NOT', it simply calls the next
        level of the precedence hierarchy, `parse_comparison()`.
        """
        
        if (self.current_token()[0] == 'NOT'): # Checks for NOT

            not_token = self.current_token()[1] # Holds NOT
            self.advance() # Moves to Next Token
            not_expression = self.parse_boolean_factor() # Recursively Parses "Not" Expression
            return UnaryOperation(('NOT', not_token), not_expression)
            
        else:

            return self.parse_comparison() # No NOT - Calls Next Level of Precedence Hierarchy

    # TODO: Implement this function
    def parse_comparison(self) -> ExprType:
        """
        Why this function is needed: To parse comparison expressions like `a > b` or `x == 10`.

        What this function does: It first calls `parse_expression()` to get the left-hand side
        (an arithmetic expression). It then checks if the current token is a comparison
        operator ('==', '!=', '>', '<'). If so, it consumes the operator and calls
        `parse_expression()` again for the right-hand side, creating a `BinaryOperation` node.
        If not, it just returns the left-hand side node it already parsed.
        """
        
        left_hand_side = self.parse_expression() # Parses left_hand_side

        if (self.current_token()[0] in ('EQ', 'NEQ', 'LESS', 'GREATER')): # Checks for Comparison Token

            if (self.current_token()[0] == 'EQ'):
                comparison_type = 'EQ'
            
            elif (self.current_token()[0] == 'NEQ'):
                comparison_type = 'NEQ'

            elif (self.current_token()[0] == 'LESS'):
                comparison_type = 'LESS'

            else:
                comparison_type = 'GREATER'

            comparison_token = self.current_token()[1] # Holds Comparison Token
            self.advance() # Moves to Next Token (Right-Hand Side)
            right_hand_side = self.parse_expression() # Parses right_hand_side
            return BinaryOperation(left_hand_side, (comparison_type, comparison_token), right_hand_side)
        
        else:

            return left_hand_side # No Comparison Token - Only left_hand_side

    # TODO: Implement this function
    def parse_expression(self) -> ExprType:
        """
        Why this function is needed: To handle the lowest precedence arithmetic operators:
        addition ('+') and subtraction ('-').

        What this function does: Following the same pattern as the boolean functions, it first
        calls `parse_term()` to get a higher-precedence operand. It then loops as long as it
        sees a 'PLUS' or 'MINUS' token, building `BinaryOperation` nodes in a left-associative way.
        """
        
        left_hand_side = self.parse_term() # Parses left_hand_side

        while (self.current_token()[0] in ('PLUS', 'MINUS')): # Loop Until No PLUS or MINUS

            if (self.current_token()[0] == 'PLUS'):
                operator_type = 'PLUS'

            else:
                operator_type = 'MINUS'

            operator_token = self.current_token()[1] # Holds PLUS or MINUS
            self.advance() # Moves to Next Token (Right-Hand Side)
            right_hand_side = self.parse_term() # Parses right_hand_side

            # Creates "New" Left-Hand Side
            # If More PLUS or MINUS (Ex: A +/- B +/- C ...): Right-Hand Side -> Shifts to Left-Hand Side, Makes Room for "New" Right-Hand Side
            left_hand_side = BinaryOperation(left_hand_side, (operator_type, operator_token), right_hand_side)

        return left_hand_side

    # TODO: Implement this function
    def parse_term(self) -> ExprType:
        """
        Why this function is needed: To handle multiplication ('*'), division ('/'), and modulo ('%'),
        which have higher precedence than addition and subtraction.

        What this function does: It calls `parse_factor()` to get its operands and loops on
        '*', '/', and '%' operators. This ensures that `a + b * c` is correctly parsed as `a + (b * c)`.
        """
    
        left_hand_side = self.parse_factor() # Parses left_hand_side

        while (self.current_token()[0] in ('MULTIPLY', 'DIVIDE', 'MODULO')): # Loop Until No MULTIPLY, DIVIDE, or MODULO

            if (self.current_token()[0] == 'MULTIPLY'):
                operator_type = 'MULTIPLY'
            
            elif (self.current_token()[0] == 'DIVIDE'):
                operator_type = 'DIVIDE'

            else:
                operator_type = 'MODULO'

            operator_token = self.current_token()[1] # Holds MULTIPLY, DIVIDE, or MODULO
            self.advance() # Moves to Next Token (Right-Hand Side)
            right_hand_side = self.parse_factor() # Parses right_hand_side

            # Creates "New" Left-Hand Side
            # If More MULTIPLE, DIVIDE, or MODULO (Ex: A [*/%] B [*/%] C ...): Right-Hand Side -> Shifts to Left-Hand Side, Makes Room for "New" Right-Hand Side
            left_hand_side = BinaryOperation(left_hand_side, (operator_type, operator_token), right_hand_side)

        return left_hand_side

    # TODO: Implement this function
    def parse_factor(self) -> ExprType:
        """
        Why this function is needed: To handle unary plus and minus operators (e.g., `-5`).
        These have higher precedence than multiplication.

        What this function does: It checks for a 'PLUS' or 'MINUS' token. If found, it consumes it,
        recursively calls `parse_factor()` for the operand, and returns a `UnaryOperation` node.
        If not, it calls `parse_primary()` for the highest-precedence elements.
        """

        if (self.current_token()[0] in ('PLUS', 'MINUS')): # Checks for PLUS or MINUS

            if (self.current_token()[0] == 'PLUS'):
                operator_type = 'PLUS'
                
            else:
                operator_type = 'MINUS'

            operator_token = self.current_token()[1] # Holds PLUS or MINUS 
            self.advance() # Moves to Next Token
            operand = self.parse_factor() # Recursively Parses operand
            return UnaryOperation((operator_type, operator_token), operand)
        
        else:

            return self.parse_primary() # No PLUS or MINUS

    # TODO: Implement this function
    def parse_primary(self) -> ExprType:
        """
        Why this function is needed: This function is at the bottom of the expression parsing
        hierarchy. It handles the most basic, highest-precedence elements of expressions. These
        are the "atoms" of an expression.

        What this function does: It checks for three cases:
        1. A 'NUMBER' token.
        2. An 'IDENTIFIER' token (a variable).
        3. An opening parenthesis 'LPAREN'. If found, it recursively calls `parse_boolean_expression()`
           to parse the entire expression inside the parentheses, and then expects a closing 'RPAREN'.
           This allows for manually overriding operator precedence (e.g., `(a + b) * c`).
        """

        token_type = self.current_token()[0] # Finds Type of Current Token

        if (token_type == 'NUMBER'): # Checks for NUMBER

            number_token = self.current_token() # Holds NUMBER
            self.advance() # Moves to Next Token
            return number_token
        
        elif (token_type == 'IDENTIFIER'): # Checks for IDENTIFIER

            identifier_token = self.current_token() # Holds IDENTIFIER
            self.advance() # Moves to Next Token
            return identifier_token
        
        elif (token_type == 'LPAREN'): # Checks for LPAREN

            self.advance() # Moves Past LPAREN
            expression = self.parse_boolean_expression() # Recusrively Parses expression
            self.expect('RPAREN') # Checks for RPAREN
            return expression
        
        else: 
            raise SyntaxError("Expected NUMBER, IDENTIFIER, or LPAREN - Invalid")
